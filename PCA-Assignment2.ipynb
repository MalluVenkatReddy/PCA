{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is a projection and how is it used in PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4108fb",
   "metadata": {},
   "source": [
    "-- More generally, we'd like to find a set of vectors on which we can project our data to reduce the feature-space from n-dimensions to k-dimensions. Further, we'd like to find these vectors such that we minimize the projection error or information loss; we earlier established that we can accomplish this by finding the direction of maximum variance within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does the optimization problem in PCA work, and what is it trying to achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1966aa7",
   "metadata": {},
   "source": [
    "-- PCA trying to optimize and to calculate the planes on which max variance will be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the relationship between covariance matrices and PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395cc1e3",
   "metadata": {},
   "source": [
    "-- A*V=Lambda*V\n",
    "\n",
    "-- A is Covariance matrix\n",
    "\n",
    "-- V are the PCA Vectors, on which max variance of projected data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fddab",
   "metadata": {},
   "source": [
    "-- As stated earlier, the covariance matrix will explain the relationship between any two features in the data. This process is used in collinear variables. A positive covariance value shows a direct relationship (both variables increase or decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How does the choice of number of principal components impact the performance of PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182ef05",
   "metadata": {},
   "source": [
    "-- If our sole intention of doing PCA is for data visualization, the best number of components is 2 or 3. If we really want to reduce the size of the dataset, the best number of principal components is much less than the number of variables in the original dataset.\n",
    "\n",
    "-- As number of features decreases upto some level increases performance of PCA and beyond that decreases performance, so keeping optimum number of PCA is very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8212adf",
   "metadata": {},
   "source": [
    "#### PCA, generally called data reduction technique, is very useful feature selection technique as it uses linear algebra to transform the dataset into a compressed form. We can implement PCA feature selection technique with the help of PCA class of scikit-learn Python librar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are some common applications of PCA in data science and machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8cb2a",
   "metadata": {},
   "source": [
    "-- It is used to reduce the number of dimensions in healthcare data\n",
    "\n",
    "-- PCA can help resize an image.\n",
    "\n",
    "-- It can be used in finance to analyze stock data and forecast returns.\n",
    "\n",
    "-- PCA helps to find patterns in the high-dimensional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef436220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7.What is the relationship between spread and variance in PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f217b4",
   "metadata": {},
   "source": [
    "#### Variance is the spread of the data in a dataset. In PCA, the variables are transformed in such a way that they explain variance of the dataset in decreasing manner.\n",
    "\n",
    "-- Higher spread has higher variance and that plane selected as principal planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How does PCA use the spread and variance of the data to identify principal components?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f127bb3b",
   "metadata": {},
   "source": [
    "-- which planes has higher spread or variance are the pro=incipal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. How does PCA handle data with high variance in some dimensions but low variance in others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17978b",
   "metadata": {},
   "source": [
    "-- standardization will take care of this high and low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d2731",
   "metadata": {},
   "source": [
    "-- Principal components are independent of each other, so removes correlated features. PCA improves the performance of the ML algorithm as it eliminates correlated variables that don't contribute in any decision making. PCA helps in overcoming data overfitting issues by decreasing the number of features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
