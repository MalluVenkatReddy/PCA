{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the curse of dimensionality reduction and why is it important in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479964e",
   "metadata": {},
   "source": [
    "-- curse of dimensionality is the phenomenon in which the performance of machine learning algorithms deteriorates beyond certain number of features or dimensions increases.\n",
    "\n",
    "-- This occurs because the number of training examples requeired to accuarately represent the space grows exponentially with the number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does the curse of dimensionality impact the performance of machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9c0c1",
   "metadata": {},
   "source": [
    "-- As the dimensionality increases, the number of data points required for good performance of any machine learning algorithm increases exponentially. The reason is that, we would need more number of data points for any given combination of features, for any machine learning model to be valid.\n",
    "\n",
    "-- Performance increases upto certain number of features, beyond that performance decreases with increasing number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ffa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What are some of the consequences of the curse of dimensionality in machine learning, and how do \n",
    "they impact model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896b8af",
   "metadata": {},
   "source": [
    "-- As the number of features increases, model may confuse to prdict the proper output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c73f7bd",
   "metadata": {},
   "source": [
    "-- Machine learning can effectively analyze data with several dimensions. However, it becomes complex to develop relevant models as the number of dimensions significantly increases. You will get abnormal results when you try to analyze data in high-dimensional spaces. This situation refers to the curse of dimensionality in machine learning. It depicts the need for more computational efforts to process and analyze a machine-learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7bdf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can you explain the concept of feature selection and how it can help with dimensionality reduction?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f4b95",
   "metadata": {},
   "source": [
    "-- Feature selection is simply selecting and excluding given features without changing them.\n",
    "\n",
    "\n",
    "-- After excluding some of correlated features from dataset, it is easier to built model with lesses training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cdbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are some limitations and drawbacks of using dimensionality reduction techniques in machine \n",
    "learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644adb5",
   "metadata": {},
   "source": [
    "-- Noise and Loss of Information \n",
    "\n",
    "-- We lost some data during the dimensionality reduction process, which can impact how well future training algorithms work. It may need a lot of processing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa829f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does the curse of dimensionality relate to overfitting and underfitting in machine learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f62b1a",
   "metadata": {},
   "source": [
    "-- The more predictors you have (the higher the dimensionality), the more likely it is that it will be possible to perfectly separate the two sets of values. As a result, overfitting becomes more of an issue when you have many predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How can one determine the optimal number of dimensions to reduce data to when using \n",
    "dimensionality reduction techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f88f2",
   "metadata": {},
   "source": [
    "-- Principal Component Analysis is one of the leading linear techniques of dimensionality reduction. This method performs a direct mapping of the data to a lesser dimensional space in a way that maximizes the variance of the data in the low-dimensional representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
